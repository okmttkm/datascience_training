{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ‡ãƒ¼ã‚¿ã‚’åŠ å·¥ã™ã‚‹ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç§‹é‡ç·¨é›†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€ã®å ´æ‰€ã‚’è¨­å®š\n",
    "dataPath = \"/data\"\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿å‡ºã—\n",
    "df = pd.read_csv(dataPath + \"/train.csv\")\n",
    "scores = df[\"score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å‰å‡¦ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltkãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å„ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°\n",
    "def text_to_vector(text, model):\n",
    "    vectors = [model.wv[word] for word in text if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(train_df):\n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆã¨ã‚¹ã‚³ã‚¢ã‚’å–å¾—\n",
    "    texts = train_df[\"full_text\"]\n",
    "    \n",
    "\n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–\n",
    "    tokenized_texts = [word_tokenize(text.lower()) for text in texts]\n",
    "\n",
    "    # Word2Vecãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´\n",
    "    word2vec_model = Word2Vec(tokenized_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "    # å„ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—\n",
    "    text_vectors = np.array([text_to_vector(text, word2vec_model) for text in tokenized_texts])\n",
    "\n",
    "    return text_vectors, word2vec_model\n",
    "\n",
    "# DataFrameã«å«ã¾ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã•ã‚ŒãŸtext_vectorã‚’å–å¾—\n",
    "text_vectors, word2vec_model = get_text_vectors(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectors_df = pd.DataFrame(text_vectors)\n",
    "text_vectors_df['score'] = df[['score']].copy()\n",
    "# text_vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors_with_model(train_df, word2vec_model):\n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆã¨ã‚¹ã‚³ã‚¢ã‚’å–å¾—\n",
    "    texts = train_df[\"full_text\"]\n",
    "    \n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–\n",
    "    tokenized_texts = [word_tokenize(text.lower()) for text in texts]\n",
    "\n",
    "    # å„ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—\n",
    "    text_vectors = np.array([text_to_vector(text, word2vec_model) for text in tokenized_texts])\n",
    "\n",
    "    return text_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å­¦ç¿’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_by_randomForest(text_vectors_df, n_estimators, random_state=42):\n",
    "    feature_columns = [i for i in text_vectors_df.columns if i != \"score\"]\n",
    "    train_df = text_vectors_df[feature_columns]\n",
    "    target = text_vectors_df[[\"score\"]]\n",
    "\n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚’è¨“ç·´ã‚»ãƒƒãƒˆã‚’ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«åˆ†å‰²\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_df, target, test_size=0.2, random_state=42)   \n",
    "\n",
    "    # ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆåˆ†é¡å™¨ã‚’è¨“ç·´\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹äºˆæ¸¬\n",
    "    y_pred = model.predict(X_test)\n",
    "    kappa_quadratic = cohen_kappa_score(y_test, y_pred, weights=\"quadratic\")\n",
    "    print(\"Weighted Kappa äºŒä¹—é‡ã¿ä»˜ã‘ï¼š\", kappa_quadratic)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = train_by_randomForest(text_vectors_df, n_estimators=100)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### äºˆæ¸¬ã¨Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿å‡ºã—\n",
    "test_df = pd.read_csv(dataPath + \"/test.csv\")\n",
    "\n",
    "# DataFrameã«å«ã¾ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã•ã‚ŒãŸtext_vectorã‚’å–å¾—\n",
    "test_text_vectors = get_text_vectors_with_model(test_df, word2vec_model)\n",
    "\n",
    "# text_vectorã‚’ä½¿ã£ã¦ã€äºˆæ¸¬ã®å®Ÿè¡Œ\n",
    "test_pred = model.predict(test_text_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = test_df[[\"essay_id\"]].copy()\n",
    "submission_df['score'] = test_pred\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.utils import resample\n",
    "import nltk\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€ã®å ´æ‰€ã‚’è¨­å®š\n",
    "dataPath = \"/data\"\n",
    "# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿å‡ºã—\n",
    "df = pd.read_csv(dataPath + \"/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã®æ•°ã‚’ç¢ºèª\n",
    "df.groupby('score').apply(lambda x:x['score'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚¹ã‚³ã‚¢6ã®æ•°ã«åˆã‚ã›ã¦ã‚‚ã€156 x 6 = 936å€‹ã®ãƒ‡ãƒ¼ã‚¿ãŒå–ã‚Œã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸã„ç·ãƒ‡ãƒ¼ã‚¿æ•°\n",
    "total_sample_size = 2000\n",
    "\n",
    "# å„ã‚¹ã‚³ã‚¢ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ãƒ‡ãƒ¼ã‚¿æ•°ã‚’è¨ˆç®—\n",
    "unique_scores = df['score'].unique()\n",
    "min_count = min(df['score'].value_counts())\n",
    "sample_per_score = total_sample_size // len(unique_scores)\n",
    "\n",
    "# å„ã‚¹ã‚³ã‚¢ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "sampled_data = []\n",
    "\n",
    "for score in unique_scores:\n",
    "    score_data = df[df['score'] == score]\n",
    "    if len(score_data) >= sample_per_score:\n",
    "        sampled = resample(score_data, n_samples=sample_per_score, random_state=42)\n",
    "    else:\n",
    "        sampled = score_data\n",
    "    sampled_data.append(sampled)\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ\n",
    "final_sample = pd.concat(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿æ•°ç¢ºèª\n",
    "final_sample.groupby('score').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å­¦ç¿’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿å®šç¾©\n",
    "data = final_sample.copy()\n",
    "\n",
    "data['score'] = data['score'] - 1  # ã‚¹ã‚³ã‚¢ã‚’0-5ã«å¤‰æ›\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ†å‰²\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(data['full_text'], data['score'], test_size=0.2, random_state=42, stratify=data['score'])\n",
    "\n",
    "# ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®æº–å‚™\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ\n",
    "class EssayDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "train_dataset = EssayDataset(train_texts.tolist(), train_labels.tolist(), tokenizer, max_len=512)\n",
    "val_dataset = EssayDataset(val_texts.tolist(), val_labels.tolist(), tokenizer, max_len=512)\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\n",
    "\n",
    "# è©•ä¾¡æŒ‡æ¨™ã®å®šç¾©\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred, average='weighted')\n",
    "    acc = accuracy_score(labels, pred)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¼•æ•°ã®è¨­å®š\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Trainerã®ä½œæˆ\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿè¡Œ\n",
    "trainer.train()\n",
    "\n",
    "# è©•ä¾¡ã®å®Ÿè¡Œ\n",
    "trainer.evaluate()\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›\n",
    "model.save_pretrained('./bert-base-uncased-model-trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ‡ãƒ¼ã‚¿æ•°:å‰åŠ100å€‹  \n",
    "{'eval_loss': 1.7269268035888672,\n",
    " 'eval_accuracy': 0.25,\n",
    " 'eval_f1': 0.2375,\n",
    " 'eval_precision': 0.48680555555555555,\n",
    " 'eval_recall': 0.25,\n",
    " 'eval_runtime': 3.1969,\n",
    " 'eval_samples_per_second': 6.256,\n",
    " 'eval_steps_per_second': 0.938,\n",
    " 'epoch': 3.0}  \n",
    " ãƒ‡ãƒ¼ã‚¿æ•°:å‰åŠ1,000å€‹ å®Ÿè¡Œæ™‚é–“:23min  \n",
    " {'eval_loss': 1.074561357498169,\n",
    " 'eval_accuracy': 0.52,\n",
    " 'eval_f1': 0.48400593321739693,\n",
    " 'eval_precision': 0.4655379723734051,\n",
    " 'eval_recall': 0.52,\n",
    " 'eval_runtime': 30.6655,\n",
    " 'eval_samples_per_second': 6.522,\n",
    " 'eval_steps_per_second': 0.815,\n",
    " 'epoch': 3.0}  \n",
    " ãƒ‡ãƒ¼ã‚¿æ•°:936å€‹ å„ã‚¹ã‚³ã‚¢156å€‹ãšã¤ å®Ÿè¡Œæ™‚é–“:21min  \n",
    " {'eval_loss': 1.1392934322357178,\n",
    " 'eval_accuracy': 0.5,\n",
    " 'eval_f1': 0.4120386813326839,\n",
    " 'eval_precision': 0.5260695493022192,\n",
    " 'eval_recall': 0.5,\n",
    " 'eval_runtime': 29.1307,\n",
    " 'eval_samples_per_second': 6.454,\n",
    " 'eval_steps_per_second': 0.824,\n",
    " 'epoch': 3.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†å‰²ã—ã¦ãŠã„ãŸãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€é‡ã¿ä»˜ãKappaã®è¨ˆç®—ã‚’ã™ã‚‹\n",
    "# è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š\n",
    "model.eval()\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–\n",
    "encoded_input = tokenizer(val_texts.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ã‚’ä¸ãˆã¦æ¨è«–ã‚’è¡Œã†\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoded_input)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ­£è§£ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡º\n",
    "true_labels = val_labels.tolist()\n",
    "# äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "predicted_labels = predictions\n",
    "# é‡ã¿ä»˜ãKappaã‚’è¨ˆç®—\n",
    "weighted_kappa = cohen_kappa_score(true_labels, predicted_labels, weights='quadratic')\n",
    "print('é‡ã¿ä»˜ãKappa:', weighted_kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kaggleæå‡ºç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (kaggleæå‡ºç”¨)ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã¸ã®é©ç”¨\n",
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿å‡ºã—\n",
    "test_df = pd.read_csv(dataPath + \"/test.csv\")\n",
    "test_texts = test_df['full_text'].copy()\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–\n",
    "test_encoded_input = tokenizer(test_texts.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ã‚’ä¸ãˆã¦æ¨è«–ã‚’è¡Œã†\n",
    "with torch.no_grad():\n",
    "    outputs = model(**test_encoded_input)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = test_df[[\"essay_id\"]].copy()\n",
    "submission_df['score'] = predictions\n",
    "submission_df['score'] = submission_df['score'] + 1 # äºˆæ¸¬çµæœã¯0-5ã§å‡ºåŠ›ã•ã‚Œã‚‹ã®ã§ +1ã—ã¦å…ƒãƒ‡ãƒ¼ã‚¿ã®1-6ã«åˆã‚ã›ã‚‹\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å­¦ç¿’æ¸ˆBERTãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸæ¨è«–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_bert(bert_model, input_token) -> list():\n",
    "    \"\"\"\n",
    "    æ—¢å­˜BERTãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸæ¨è«–\n",
    "\n",
    "    Args:\n",
    "        bert_model: å­¦ç¿’æ¸ˆBERTãƒ¢ãƒ‡ãƒ«\n",
    "        input_token: torkenizeã•ã‚ŒãŸå…¥åŠ›ãƒ‡ãƒ¼ã‚¿\n",
    "\n",
    "    Returns:\n",
    "        predictions: æ¨è«–çµæœã®ãƒªã‚¹ãƒˆ\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**input_token)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, axis=1).tolist()\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ç¿’æ¸ˆãƒ¢ãƒ‡ãƒ«ã®èª­ã¿å‡ºã—\n",
    "model_path = '/data/bert-base-uncased-model-trained'\n",
    "if os.path.isdir(model_path):\n",
    "    model_trained = BertForSequenceClassification.from_pretrained(model_path, num_labels=6)\n",
    "    model_trained.eval()\n",
    "else:\n",
    "    print('ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã„')\n",
    "\n",
    "# tokenizerã®èª­ã¿å‡ºã—\n",
    "tokenizer_path = '/data/bert-base-uncased-tokenizer'\n",
    "if os.path.isdir(tokenizer_path):\n",
    "    tokenizer  = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "else:\n",
    "    print('ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã„')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™\n",
    "eval_data = df.copy()\n",
    "eval_data = df[~df['essay_id'].isin(final_sample['essay_id'])]\n",
    "eval_data = eval_data.sample(100, random_state=42)\n",
    "eval_texts = eval_data['full_text'].tolist()\n",
    "input_token = tokenizer(eval_texts, padding=True, truncation=True, return_tensors='pt', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_with_bert(model_trained, input_token)\n",
    "\n",
    "# Kappaã®è¨ˆç®—\n",
    "# æ­£è§£ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡º\n",
    "true_labels = eval_data['score'].tolist()\n",
    "# äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "predicted_labels = predictions\n",
    "# é‡ã¿ä»˜ãKappaã‚’è¨ˆç®—\n",
    "weighted_kappa = cohen_kappa_score(true_labels, predicted_labels, weights='quadratic')\n",
    "print('é‡ã¿ä»˜ãKappa:', weighted_kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å­¦ç¿’æ¸ˆBERTã‚’ä½¿ã£ãŸæ¨è«–2 kaggleã®ãƒ¡ãƒ¢ãƒªä¸è¶³å¯¾ç­–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®é«˜ã„æ¨è«–ãƒ«ãƒ¼ãƒ—ã‚’ä½¿ç”¨ã™ã‚‹  \n",
    "- è©•ä¾¡æ™‚ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ 8 -> 4ã«å¤‰æ›´ã™ã‚‹  \n",
    "BERTãƒ¢ãƒ‡ãƒ«ã¯ä¸Šã®ã‚³ãƒ¼ãƒ‰ã‹ã‚‰æµç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class EssayDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_len=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "        )\n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        }\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™\n",
    "eval_data = df.copy()\n",
    "eval_data = df[~df['essay_id'].isin(final_sample['essay_id'])]\n",
    "eval_data = eval_data.sample(100, random_state=42)\n",
    "eval_dataset = EssayDataset(eval_data['full_text'].tolist(), tokenizer=tokenizer, max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# è©•ä¾¡æ™‚ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æŒ‡å®š\n",
    "eval_batch_size = 4\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ä½œæˆ\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=eval_batch_size)\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š\n",
    "model_trained.eval()\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# æ¨è«–çµæœã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(eval_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = model_trained(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "# äºˆæ¸¬çµæœã®ç¢ºèª\n",
    "print(all_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kappaã®è¨ˆç®—\n",
    "# æ­£è§£ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡º\n",
    "true_labels = eval_data['score'].tolist()\n",
    "# äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "predicted_labels = all_predictions\n",
    "# é‡ã¿ä»˜ãKappaã‚’è¨ˆç®—\n",
    "weighted_kappa = cohen_kappa_score(true_labels, predicted_labels, weights='quadratic')\n",
    "print('é‡ã¿ä»˜ãKappa:', weighted_kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BERTã®æ”¹è‰¯å‹ã§ã€è¨ˆç®—åŠ¹ç‡å‘ä¸ŠãŒã§ãã‚‹ã‹ã‚‚ã—ã‚Œãªã„  \n",
    "- ç¾çŠ¶ã®BERTã¯å­¦ç¿’è‡ªä½“ã«æ™‚é–“ã‹ã‹ã‚‹ & kaggleæå‡ºæ™‚ã®æ¨è«–ã‚‚ã‹ãªã‚Šæ™‚é–“ã‹ã‹ã£ã¦ã„ã‚‹ã®ã§ã€æ”¹å–„ã™ã‚‹ã‹è©¦ã—ã¦ã¿ã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import DebertaTokenizer, DebertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ‡ãƒ¼ã‚¿èª­ã¿å‡ºã—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€ã®å ´æ‰€ã‚’è¨­å®š\n",
    "dataPath = \"/data\"\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿å‡ºã—\n",
    "df = pd.read_csv(dataPath + \"/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸã„ç·ãƒ‡ãƒ¼ã‚¿æ•°\n",
    "total_sample_size = 2000\n",
    "\n",
    "# å„ã‚¹ã‚³ã‚¢ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ãƒ‡ãƒ¼ã‚¿æ•°ã‚’è¨ˆç®—\n",
    "unique_scores = df['score'].unique()\n",
    "min_count = min(df['score'].value_counts())\n",
    "sample_per_score = total_sample_size // len(unique_scores)\n",
    "\n",
    "# å„ã‚¹ã‚³ã‚¢ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "sampled_data = []\n",
    "\n",
    "for score in unique_scores:\n",
    "    score_data = df[df['score'] == score]\n",
    "    if len(score_data) >= sample_per_score:\n",
    "        sampled = resample(score_data, n_samples=sample_per_score, random_state=42)\n",
    "    else:\n",
    "        sampled = score_data\n",
    "    sampled_data.append(sampled)\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ\n",
    "final_sample = pd.concat(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿å®šç¾©\n",
    "data = final_sample.copy()\n",
    "data['score'] = data['score'] - 1  # ã‚¹ã‚³ã‚¢ã‚’0-5ã«å¤‰æ›\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ†å‰²\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(data['full_text'], data['score'], test_size=0.2)\n",
    "\n",
    "# DeBERTaç”¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®æº–å‚™\n",
    "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ\n",
    "class EssayDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_len=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "        )\n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        }\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåŒ–\n",
    "train_dataset = EssayDataset(train_texts.tolist(), train_labels.tolist(), tokenizer, max_len=512)\n",
    "val_dataset = EssayDataset(val_texts.tolist(), val_labels.tolist(), tokenizer, max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# DeBERTaãƒ¢ãƒ‡ãƒ«ã®æº–å‚™\n",
    "model = DebertaForSequenceClassification.from_pretrained('microsoft/deberta-base', num_labels=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è©•ä¾¡æŒ‡æ¨™ã®å®šç¾©\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred, average='weighted')\n",
    "    acc = accuracy_score(labels, pred)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¼•æ•°ã®è¨­å®š\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainerã®ä½œæˆ\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã™ãã‚«ãƒ¼ãƒãƒ«ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ã¦ã—ã¾ã†ã®ã§ã€DeBERTaå­¦ç¿’ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§è¡Œã„ã€å­¦ç¿’æ¸ˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã«ã™ã‚‹\n",
    "\n",
    "# # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿè¡Œ\n",
    "# trainer.train()\n",
    "\n",
    "# # è©•ä¾¡ã®å®Ÿè¡Œ\n",
    "# trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å­¦ç¿’æ¸ˆDeBERTaã‚’ä½¿ã£ãŸæ¨è«–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 02:30:44.800767: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-24 02:30:44.868506: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-24 02:30:45.166900: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-24 02:30:45.166944: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-24 02:30:45.220081: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-24 02:30:45.328832: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-24 02:30:45.330152: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-24 02:30:46.201823: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import DebertaTokenizer, DebertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€ã®å ´æ‰€ã‚’è¨­å®š\n",
    "dataPath = \"/data\"\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿å‡ºã—\n",
    "df = pd.read_csv(dataPath + \"/train.csv\")\n",
    "\n",
    "# å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿å®šç¾©\n",
    "data = df.copy()\n",
    "data['score'] = data['score'] - 1  # ã‚¹ã‚³ã‚¢ã‚’0-5ã«å¤‰æ›\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ†å‰²\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(data['full_text'], data['score'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ã—ãŸãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ãƒ­ãƒ¼ãƒ‰\n",
    "tokenizer = DebertaTokenizer.from_pretrained('/data/deberta-tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ\n",
    "class EssayDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_len=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "        )\n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        }\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‹•ä½œç¢ºèªç”¨ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "val_dataset = EssayDataset(val_texts.tolist(), tokenizer=tokenizer, max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ç¿’æ¸ˆãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰\n",
    "model = DebertaForSequenceClassification.from_pretrained('/data/deberta-model-trained', num_labels=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ä½œæˆ\n",
    "val_loader = DataLoader(val_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaForSequenceClassification(\n",
       "  (deberta): DebertaModel(\n",
       "    (embeddings): DebertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
       "      (LayerNorm): DebertaLayerNorm()\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(1024, 768)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨è«–ã®å®Ÿè¡Œ\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(model.device)\n",
    "        attention_mask = batch['attention_mask'].to(model.device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        predictions.extend(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é‡ã¿ä»˜ãKappa: 0.7520735832970541\n"
     ]
    }
   ],
   "source": [
    "# Kappaã®è¨ˆç®—\n",
    "# æ­£è§£ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡º\n",
    "true_labels = val_labels.tolist()\n",
    "# äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "predicted_labels = predictions\n",
    "# é‡ã¿ä»˜ãKappaã‚’è¨ˆç®—\n",
    "weighted_kappa = cohen_kappa_score(true_labels, predicted_labels, weights='quadratic')\n",
    "print('é‡ã¿ä»˜ãKappa:', weighted_kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å²¡æœ¬ç·¨é›†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãƒ‡ãƒ¼ã‚¿ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/test.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes.to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç‰¹å¾´é‡ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(df):\n",
    "    \"\"\"ç‰¹å¾´é‡ä½œæˆé–¢æ•°\n",
    "\n",
    "    ç‰¹å¾´é‡ã®èª¬æ˜\n",
    "        text_len:ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•\n",
    "        space_count:ç©ºç™½ã®æ•°\n",
    "        word_len_avg:ä¸€ç¯€ã®å¹³å‡çš„ãªé•·ã•\n",
    "        I-cnt:â€ç§â€ã¨ã„ã†å˜èªã®å‡ºç¾é »åº¦\n",
    "\n",
    "    Args:\n",
    "        df(pandas.DataFrame):åŠ å·¥ã—ãŸã„ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "    Return:\n",
    "        pandas.DataFrame:åŠ å·¥å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    df['text_len'] = df.full_text.str.len()\n",
    "    df['space_count'] = df.full_text.str.count(' ')\n",
    "    df['word_len_avg'] = (df.text_len - df.space_count) / (df.space_count + 1)\n",
    "    df['I-cnt'] = df.full_text.str.startswith('I') + df.full_text.str.count('. I ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = processing(train_df)\n",
    "processed_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test = processing(test_df)\n",
    "processed_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å˜èªç‰¹å¾´é‡ä½œæˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å˜èªã®å‡ºç¾é »åº¦ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_freq(df):\n",
    "    #ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç”Ÿæˆ\n",
    "    vec_count = CountVectorizer()\n",
    "    vec_count.fit(df.full_text)\n",
    "    X = vec_count.transform(df.full_text)\n",
    "    #å˜èªã‚’ã‚«ãƒ©ãƒ åŒ–ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«è¿½åŠ \n",
    "    word_df = pd.DataFrame(X.toarray())\n",
    "    word_df.columns = vec_count.get_feature_names_out()\n",
    "    #df = pd.concat([df, word_df], axis=1)\n",
    "    #å˜èªã®å‡ºç¾é »åº¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ\n",
    "    #word_df = pd.DataFrame(word_df.sum(axis=0).sort_values(ascending=False).reset_index())\n",
    "    #word_df.columns = ['word', 'count']\n",
    "    return word_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def split_data(df):\n",
    "    num = len(df) // 4\n",
    "    q2 = num * 2\n",
    "    q3 = num * 3\n",
    "    q1_df = df.iloc[:num,:]\n",
    "    q2_df = df.iloc[num:q2,:]\n",
    "    q3_df = df.iloc[q2:q3,:]\n",
    "    q4_df = df.iloc[q3:,:]\n",
    "    return q1_df,q2_df,q3_df,q4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df_train = check_freq(processed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([processed_train,word_df_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df_test = check_freq(processed_test)\n",
    "test_df = pd.concat([processed_test,word_df_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('/data/add_word_train.csv',index=False)\n",
    "test_df.to_csv('/data/add_word_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰å‰Šé™¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/data/add_word_train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/data/add_word_test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#è‹±èªã®ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "#ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã‚’é›†åˆã¨ã—ã¦æ ¼ç´ï¼ˆå¾Œã§é›†åˆåŒå£«ã®æ¯”è¼ƒæ¼”ç®—ã‚’è¡Œã†ãŸã‚ï¼‰\n",
    "stop_words_set = set(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_stopword(df):\n",
    "    \n",
    "    #å˜èªãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã«ã©ã‚Œã ã‘ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹ã®ã‹ç¢ºèª\n",
    "    columns_set = set(df.columns)\n",
    "\n",
    "    #å…±é€šå˜èªæŠ½å‡º\n",
    "    and_set = columns_set & stop_words_set\n",
    "\n",
    "    #å˜èªãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å­˜åœ¨ã—ãªã‹ã£ãŸã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰æ•°æŠ½å‡º\n",
    "    before = len(df.columns)\n",
    "    tmp_df = df.drop(columns=list(and_set))\n",
    "    after = len(tmp_df.columns)\n",
    "\n",
    "    #ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã®é™¤å»ã€é™¤å»å‰å¾Œã§çŸ›ç›¾ãŒãªã„ã‹ç¢ºèª\n",
    "    print(f'å‡¦ç†å‰ã‚«ãƒ©ãƒ æ•°ï¼š{before} å‡¦ç†å¾Œã‚«ãƒ©ãƒ æ•°ï¼š{after} å·®ï¼š{before-after}')\n",
    "    if before - after == len(and_set):\n",
    "        print('å‡¦ç†ã«å•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“')\n",
    "    else:\n",
    "        print('å‡¦ç†ã«çŸ›ç›¾ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™')\n",
    "\n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = drop_stopword(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = drop_stopword(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.sum().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_sum = tmp_df.sum(numeric_only=True).to_frame()\n",
    "tmp_sum.columns = ['count']\n",
    "tmp_sum = tmp_sum.sort_values('count',ascending=False).round(1)\n",
    "tmp_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=((15,8)))\n",
    "x = np.arange(1,11)\n",
    "y = []\n",
    "l = [len(train_df.columns)] * 10\n",
    "for i in range(1, 11):\n",
    "    y.append(len(tmp_sum.query('count <= @i')))\n",
    "\n",
    "ax[0].plot(x, y, marker='.', markersize=10)\n",
    "ax[0].set_title('å˜èªã®å‡ºç¾é »åº¦ã®é–¾å€¤ VS è½ã¨ã•ã‚Œã‚‹ç‰¹å¾´é‡')\n",
    "ax[0].set_xlabel('å˜èªã®å‡ºç¾é »åº¦ã®é–¾å€¤')\n",
    "ax[0].set_ylabel('è½ã¨ã•ã‚Œã‚‹ç‰¹å¾´é‡')\n",
    "for i, txt in enumerate(y):\n",
    "    ax[0].text(x[i], y[i], txt)\n",
    "\n",
    "y = np.array(l) - np.array(y)\n",
    "ax[1].plot(x, y, marker='.', markersize=10)\n",
    "ax[1].set_title('å˜èªã®å‡ºç¾é »åº¦ã®é–¾å€¤ VS æ®‹ã‚‹ç‰¹å¾´é‡æ•°')\n",
    "ax[1].set_xlabel('å˜èªã®å‡ºç¾é »åº¦ã®é–¾å€¤')\n",
    "ax[1].set_ylabel('æ®‹ã‚‹ç‰¹å¾´é‡æ•°')\n",
    "for i, txt in enumerate(y):\n",
    "    ax[1].text(x[i], y[i], txt)\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å‡ºç¾é »åº¦ãŒï¼“ä»¥ä¸‹ã®ç‰¹å¾´é‡ã‚’å‰Šé™¤ã™ã‚‹ã“ã¨ã§ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚ˆã‚Šã‚‚ç‰¹å¾´é‡æ•°ã‚’æŠ‘ãˆã‚‰ã‚Œã‚‹\n",
    "- ãŸã ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚‚åŒæ§˜ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã§ã‚ã‚‹ã“ã¨ãŒå‰æã¨ãªã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å‰å‡¦ç†å¾Œãƒ‡ãƒ¼ã‚¿å‡ºåŠ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./data/processed_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('./data/processed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

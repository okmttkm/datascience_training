{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データを加工するノートブック"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 秋野編集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データフォルダの場所を設定\n",
    "dataPath = \"/data\"\n",
    "\n",
    "# データの読み出し\n",
    "df = pd.read_csv(dataPath + \"/train.csv\")\n",
    "scores = df[\"score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltkデータ読み込み\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各テキストのベクトルを計算する関数\n",
    "def text_to_vector(text, model):\n",
    "    vectors = [model.wv[word] for word in text if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(train_df):\n",
    "    # テキストとスコアを取得\n",
    "    texts = train_df[\"full_text\"]\n",
    "    \n",
    "\n",
    "    # テキストをトークン化\n",
    "    tokenized_texts = [word_tokenize(text.lower()) for text in texts]\n",
    "\n",
    "    # Word2Vecモデルの訓練\n",
    "    word2vec_model = Word2Vec(tokenized_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "    # 各テキストのベクトルを計算\n",
    "    text_vectors = np.array([text_to_vector(text, word2vec_model) for text in tokenized_texts])\n",
    "\n",
    "    return text_vectors, word2vec_model\n",
    "\n",
    "# DataFrameに含まれたテキストデータから、トークン化されたtext_vectorを取得\n",
    "text_vectors, word2vec_model = get_text_vectors(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectors_df = pd.DataFrame(text_vectors)\n",
    "text_vectors_df['score'] = df[['score']].copy()\n",
    "# text_vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors_with_model(train_df, word2vec_model):\n",
    "    # テキストとスコアを取得\n",
    "    texts = train_df[\"full_text\"]\n",
    "    \n",
    "    # テキストをトークン化\n",
    "    tokenized_texts = [word_tokenize(text.lower()) for text in texts]\n",
    "\n",
    "    # 各テキストのベクトルを計算\n",
    "    text_vectors = np.array([text_to_vector(text, word2vec_model) for text in tokenized_texts])\n",
    "\n",
    "    return text_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_by_randomForest(text_vectors_df, n_estimators, random_state=42):\n",
    "    feature_columns = [i for i in text_vectors_df.columns if i != \"score\"]\n",
    "    train_df = text_vectors_df[feature_columns]\n",
    "    target = text_vectors_df[[\"score\"]]\n",
    "\n",
    "    # データを訓練セットをテストセットに分割\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_df, target, test_size=0.2, random_state=42)   \n",
    "\n",
    "    # ランダムフォレスト分類器を訓練\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # テストデータに対する予測\n",
    "    y_pred = model.predict(X_test)\n",
    "    kappa_quadratic = cohen_kappa_score(y_test, y_pred, weights=\"quadratic\")\n",
    "    print(\"Weighted Kappa 二乗重み付け：\", kappa_quadratic)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = train_by_randomForest(text_vectors_df, n_estimators=100)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測とSubmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの読み出し\n",
    "test_df = pd.read_csv(dataPath + \"/test.csv\")\n",
    "\n",
    "# DataFrameに含まれたテキストデータから、トークン化されたtext_vectorを取得\n",
    "test_text_vectors = get_text_vectors_with_model(test_df, word2vec_model)\n",
    "\n",
    "# text_vectorを使って、予測の実行\n",
    "test_pred = model.predict(test_text_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = test_df[[\"essay_id\"]].copy()\n",
    "submission_df['score'] = test_pred\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データフォルダの場所を設定\n",
    "dataPath = \"/data\"\n",
    "# データの読み出し\n",
    "df = pd.read_csv(dataPath + \"/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの数を確認\n",
    "df.groupby('score').apply(lambda x:x['score'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スコア6の数に合わせても、156 x 6 = 936個のデータが取れる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スコア毎に同数のデータを取得する\n",
    "min_samples = df.groupby('score').size().min()\n",
    "balanced_data = df.groupby('score').apply(lambda x:x.sample(n=min_samples)).reset_index(drop=True)\n",
    "balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatGPTサンプルコード\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# データフォルダの場所を設定\n",
    "dataPath = \"/data\"\n",
    "# データの読み出し\n",
    "df = pd.read_csv(dataPath + \"/train.csv\")\n",
    "\n",
    "# データセットの読み込み\n",
    "# data = df.head(1000)\n",
    "\n",
    "# スコア毎に同数のデータを取得する\n",
    "min_samples = df.groupby('score').size().min()\n",
    "data = df.groupby('score').apply(lambda x:x.sample(n=min_samples)).reset_index(drop=True)\n",
    "\n",
    "data['score'] = data['score'] - 1  # スコアを0-5に変換\n",
    "\n",
    "# データセットの分割\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(data['full_text'], data['score'], test_size=0.2, random_state=42, stratify=data['score'])\n",
    "\n",
    "# トークナイザーの準備\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# カスタムデータセットの作成\n",
    "class EssayDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "train_dataset = EssayDataset(train_texts.tolist(), train_labels.tolist(), tokenizer, max_len=512)\n",
    "val_dataset = EssayDataset(val_texts.tolist(), val_labels.tolist(), tokenizer, max_len=512)\n",
    "\n",
    "# モデルの準備\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\n",
    "\n",
    "# 評価指標の定義\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred, average='weighted')\n",
    "    acc = accuracy_score(labels, pred)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# トレーニング引数の設定\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Trainerの作成\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# トレーニングの実行\n",
    "trainer.train()\n",
    "\n",
    "# 評価の実行\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ数:前半100個  \n",
    "{'eval_loss': 1.7269268035888672,\n",
    " 'eval_accuracy': 0.25,\n",
    " 'eval_f1': 0.2375,\n",
    " 'eval_precision': 0.48680555555555555,\n",
    " 'eval_recall': 0.25,\n",
    " 'eval_runtime': 3.1969,\n",
    " 'eval_samples_per_second': 6.256,\n",
    " 'eval_steps_per_second': 0.938,\n",
    " 'epoch': 3.0}  \n",
    " データ数:前半1,000個 実行時間:23min  \n",
    " {'eval_loss': 1.074561357498169,\n",
    " 'eval_accuracy': 0.52,\n",
    " 'eval_f1': 0.48400593321739693,\n",
    " 'eval_precision': 0.4655379723734051,\n",
    " 'eval_recall': 0.52,\n",
    " 'eval_runtime': 30.6655,\n",
    " 'eval_samples_per_second': 6.522,\n",
    " 'eval_steps_per_second': 0.815,\n",
    " 'epoch': 3.0}  \n",
    " データ数:936個 各スコア156個ずつ 実行時間:21min  \n",
    " {'eval_loss': 1.1392934322357178,\n",
    " 'eval_accuracy': 0.5,\n",
    " 'eval_f1': 0.4120386813326839,\n",
    " 'eval_precision': 0.5260695493022192,\n",
    " 'eval_recall': 0.5,\n",
    " 'eval_runtime': 29.1307,\n",
    " 'eval_samples_per_second': 6.454,\n",
    " 'eval_steps_per_second': 0.824,\n",
    " 'epoch': 3.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割しておいたテストデータを用いて、重み付きKappaの計算をする\n",
    "# 評価モードに設定\n",
    "model.eval()\n",
    "\n",
    "# データをトークン化\n",
    "encoded_input = tokenizer(val_texts.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# モデルに入力を与えて推論を行う\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoded_input)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解データからラベルを抽出\n",
    "true_labels = val_labels.tolist()\n",
    "# 予測データを取得\n",
    "predicted_labels = predictions\n",
    "# 重み付きKappaを計算\n",
    "weighted_kappa = cohen_kappa_score(true_labels, predicted_labels, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (kaggle提出用)テスト用データへの適用\n",
    "# テストデータの読み出し\n",
    "test_df = pd.read_csv(dataPath + \"/test.csv\")\n",
    "test_texts = test_df['full_text'].copy()\n",
    "\n",
    "# データをトークン化\n",
    "test_encoded_input = tokenizer(test_texts.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# モデルに入力を与えて推論を行う\n",
    "with torch.no_grad():\n",
    "    outputs = model(**test_encoded_input)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = test_df[[\"essay_id\"]].copy()\n",
    "submission_df['score'] = predictions\n",
    "submission_df['score'] = submission_df['score'] + 1 # 予測結果は0-5で出力されるので +1して元データの1-6に合わせる\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 岡本編集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17302</th>\n",
       "      <td>ffd378d</td>\n",
       "      <td>the story \" The Challenge of Exploing Venus \" ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17303</th>\n",
       "      <td>ffddf1f</td>\n",
       "      <td>Technology has changed a lot of ways that we l...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17304</th>\n",
       "      <td>fff016d</td>\n",
       "      <td>If you don't like sitting around all day than ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17305</th>\n",
       "      <td>fffb49b</td>\n",
       "      <td>In \"The Challenge of Exporing Venus,\" the auth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17306</th>\n",
       "      <td>fffed3e</td>\n",
       "      <td>Venus is worthy place to study but dangerous. ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17307 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                          full_text  score\n",
       "0      000d118  Many people have car where they live. The thin...      3\n",
       "1      000fe60  I am a scientist at NASA that is discussing th...      3\n",
       "2      001ab80  People always wish they had the same technolog...      4\n",
       "3      001bdc0  We all heard about Venus, the planet without a...      4\n",
       "4      002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3\n",
       "...        ...                                                ...    ...\n",
       "17302  ffd378d  the story \" The Challenge of Exploing Venus \" ...      2\n",
       "17303  ffddf1f  Technology has changed a lot of ways that we l...      4\n",
       "17304  fff016d  If you don't like sitting around all day than ...      2\n",
       "17305  fffb49b  In \"The Challenge of Exporing Venus,\" the auth...      1\n",
       "17306  fffed3e  Venus is worthy place to study but dangerous. ...      2\n",
       "\n",
       "[17307 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17307, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text\n",
       "0  000d118  Many people have car where they live. The thin...\n",
       "1  000fe60  I am a scientist at NASA that is discussing th...\n",
       "2  001ab80  People always wish they had the same technolog..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('./data/test.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essay_id     0\n",
       "full_text    0\n",
       "score        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id full_text  score\n",
       "0   object    object  int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes.to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(df):\n",
    "    \"\"\"特徴量作成関数\n",
    "\n",
    "    特徴量の説明\n",
    "        text_len:テキストの長さ\n",
    "        space_count:空白の数\n",
    "        word_len_avg:一節の平均的な長さ\n",
    "        I-cnt:”私”という単語の出現頻度\n",
    "\n",
    "    Args:\n",
    "        df(pandas.DataFrame):加工したいデータフレーム\n",
    "    Return:\n",
    "        pandas.DataFrame:加工後のデータフレーム\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    df['text_len'] = df.full_text.str.len()\n",
    "    df['space_count'] = df.full_text.str.count(' ')\n",
    "    df['word_len_avg'] = (df.text_len - df.space_count) / (df.space_count + 1)\n",
    "    df['I-cnt'] = df.full_text.str.startswith('I') + df.full_text.str.count('. I ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>text_len</th>\n",
       "      <th>space_count</th>\n",
       "      <th>word_len_avg</th>\n",
       "      <th>I-cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "      <td>2677</td>\n",
       "      <td>496</td>\n",
       "      <td>4.388330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "      <td>1669</td>\n",
       "      <td>327</td>\n",
       "      <td>4.091463</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "      <td>3077</td>\n",
       "      <td>555</td>\n",
       "      <td>4.535971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "      <td>2701</td>\n",
       "      <td>446</td>\n",
       "      <td>5.044743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>3</td>\n",
       "      <td>2208</td>\n",
       "      <td>380</td>\n",
       "      <td>4.797900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  \\\n",
       "0  000d118  Many people have car where they live. The thin...      3   \n",
       "1  000fe60  I am a scientist at NASA that is discussing th...      3   \n",
       "2  001ab80  People always wish they had the same technolog...      4   \n",
       "3  001bdc0  We all heard about Venus, the planet without a...      4   \n",
       "4  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3   \n",
       "\n",
       "   text_len  space_count  word_len_avg  I-cnt  \n",
       "0      2677          496      4.388330      1  \n",
       "1      1669          327      4.091463      2  \n",
       "2      3077          555      4.535971      0  \n",
       "3      2701          446      5.044743      0  \n",
       "4      2208          380      4.797900      2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train = processing(train_df)\n",
    "processed_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>text_len</th>\n",
       "      <th>space_count</th>\n",
       "      <th>word_len_avg</th>\n",
       "      <th>I-cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>2677</td>\n",
       "      <td>496</td>\n",
       "      <td>4.388330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>1669</td>\n",
       "      <td>327</td>\n",
       "      <td>4.091463</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>3077</td>\n",
       "      <td>555</td>\n",
       "      <td>4.535971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  text_len  \\\n",
       "0  000d118  Many people have car where they live. The thin...      2677   \n",
       "1  000fe60  I am a scientist at NASA that is discussing th...      1669   \n",
       "2  001ab80  People always wish they had the same technolog...      3077   \n",
       "\n",
       "   space_count  word_len_avg  I-cnt  \n",
       "0          496      4.388330      1  \n",
       "1          327      4.091463      2  \n",
       "2          555      4.535971      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test = processing(test_df)\n",
    "processed_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テキスト翻訳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def translate_text(text):\n",
    "    try:\n",
    "        translated = translator.translate(text,src='en',dest='ja').text\n",
    "        return translated\n",
    "    except Exception as e:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df['text_ja'] = train_df.full_text.progress_apply(translate_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#翻訳後データフレームをcsv出力\n",
    "train_df.to_csv('./data/trandlated_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単語特徴量作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語の出現頻度確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_freq(df):\n",
    "    #インスタンス生成\n",
    "    vec_count = CountVectorizer()\n",
    "    vec_count.fit(df.full_text)\n",
    "    X = vec_count.transform(df.full_text)\n",
    "    #単語をカラム化してデータフレームに追加\n",
    "    word_df = pd.DataFrame(X.toarray(), columns=vec_count.get_feature_names_out())\n",
    "    df = pd.concat([df, word_df], axis=1)\n",
    "    #単語の出現頻度データフレーム作成\n",
    "    word_df = pd.DataFrame(word_df.sum(axis=0).sort_values(ascending=False).reset_index())\n",
    "    word_df.columns = ['word', 'count']\n",
    "    return df,word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>text_len</th>\n",
       "      <th>space_count</th>\n",
       "      <th>word_len_avg</th>\n",
       "      <th>I-cnt</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>...</th>\n",
       "      <th>zygomatiz</th>\n",
       "      <th>zygomstic</th>\n",
       "      <th>zygomtic</th>\n",
       "      <th>zygosmtic</th>\n",
       "      <th>²excerpt</th>\n",
       "      <th>¹excerpt</th>\n",
       "      <th>ät</th>\n",
       "      <th>årgument</th>\n",
       "      <th>ëvening</th>\n",
       "      <th>ö_o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "      <td>2677</td>\n",
       "      <td>496</td>\n",
       "      <td>4.388330</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "      <td>1669</td>\n",
       "      <td>327</td>\n",
       "      <td>4.091463</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "      <td>3077</td>\n",
       "      <td>555</td>\n",
       "      <td>4.535971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "      <td>2701</td>\n",
       "      <td>446</td>\n",
       "      <td>5.044743</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>3</td>\n",
       "      <td>2208</td>\n",
       "      <td>380</td>\n",
       "      <td>4.797900</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64581 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  \\\n",
       "0  000d118  Many people have car where they live. The thin...      3   \n",
       "1  000fe60  I am a scientist at NASA that is discussing th...      3   \n",
       "2  001ab80  People always wish they had the same technolog...      4   \n",
       "3  001bdc0  We all heard about Venus, the planet without a...      4   \n",
       "4  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3   \n",
       "\n",
       "   text_len  space_count  word_len_avg  I-cnt  00  000  0000  ...  zygomatiz  \\\n",
       "0      2677          496      4.388330      1   0    1     0  ...          0   \n",
       "1      1669          327      4.091463      2   0    0     0  ...          0   \n",
       "2      3077          555      4.535971      0   0    0     0  ...          0   \n",
       "3      2701          446      5.044743      0   0    0     0  ...          0   \n",
       "4      2208          380      4.797900      2   0    0     0  ...          0   \n",
       "\n",
       "   zygomstic  zygomtic  zygosmtic  ²excerpt  ¹excerpt  ät  årgument  ëvening  \\\n",
       "0          0         0          0         0         0   0         0        0   \n",
       "1          0         0          0         0         0   0         0        0   \n",
       "2          0         0          0         0         0   0         0        0   \n",
       "3          0         0          0         0         0   0         0        0   \n",
       "4          0         0          0         0         0   0         0        0   \n",
       "\n",
       "   ö_o  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    0  \n",
       "\n",
       "[5 rows x 64581 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>369541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>207130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>146862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>139419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>that</td>\n",
       "      <td>115132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word   count\n",
       "0   the  369541\n",
       "1    to  207130\n",
       "2   and  146862\n",
       "3    of  139419\n",
       "4  that  115132"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#訓練データのテキストを単語に分解\n",
    "train_df, word_df_train = check_freq(processed_train)\n",
    "display(train_df.head())\n",
    "display(word_df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>text_len</th>\n",
       "      <th>space_count</th>\n",
       "      <th>word_len_avg</th>\n",
       "      <th>I-cnt</th>\n",
       "      <th>000</th>\n",
       "      <th>12</th>\n",
       "      <th>20</th>\n",
       "      <th>2006</th>\n",
       "      <th>...</th>\n",
       "      <th>worked</th>\n",
       "      <th>working</th>\n",
       "      <th>works</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>2677</td>\n",
       "      <td>496</td>\n",
       "      <td>4.388330</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>1669</td>\n",
       "      <td>327</td>\n",
       "      <td>4.091463</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>3077</td>\n",
       "      <td>555</td>\n",
       "      <td>4.535971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 473 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  text_len  \\\n",
       "0  000d118  Many people have car where they live. The thin...      2677   \n",
       "1  000fe60  I am a scientist at NASA that is discussing th...      1669   \n",
       "2  001ab80  People always wish they had the same technolog...      3077   \n",
       "\n",
       "   space_count  word_len_avg  I-cnt  000  12  20  2006  ...  worked  working  \\\n",
       "0          496      4.388330      1    1   1   1     1  ...       0        0   \n",
       "1          327      4.091463      2    0   0   0     0  ...       1        2   \n",
       "2          555      4.535971      0    0   0   0     0  ...       0        0   \n",
       "\n",
       "   works  world  would  year  years  you  your  yourself  \n",
       "0      0      1      0     1      1    6     1         0  \n",
       "1      1      0      3     0      0    5     0         0  \n",
       "2      0      0      0     0      0    1     0         1  \n",
       "\n",
       "[3 rows x 473 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  count\n",
       "0   the     57\n",
       "1    to     45\n",
       "2  that     43\n",
       "3    of     35\n",
       "4   and     29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#テストデータのテキストを単語に分解\n",
    "test_df, word_df_test = check_freq(processed_test)\n",
    "display(test_df.head())\n",
    "display(word_df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ストップワード削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#英語のストップワードダウンロード\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "#ストップワードを集合として格納（後で集合同士の比較演算を行うため）\n",
    "stop_words_set = set(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def drop_stopword(df):\n",
    "    \n",
    "    #単語データフレーム内にどれだけストップワードが含まれるのか確認\n",
    "    columns_set = set(df.columns)\n",
    "\n",
    "    #共通単語抽出\n",
    "    and_set = columns_set & stop_words_set\n",
    "\n",
    "    #単語データフレームに存在しなかったストップワード数抽出\n",
    "    before = len(df.columns)\n",
    "    diff_list = list(columns_set - and_set)\n",
    "    df = df[diff_list].copy()\n",
    "    after = len(df.columns)\n",
    "\n",
    "    #ストップワードの除去、除去前後で矛盾がないか確認\n",
    "    print(f'処理前カラム数：{before}　処理後カラム数：{after}　差：{before-after}')    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = drop_stopword(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([processed_train,tmp_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contunes        1\n",
       "shafts          1\n",
       "betrayel        1\n",
       "coprrosive      1\n",
       "disposed        4\n",
       "               ..\n",
       "barriers       15\n",
       "mountrains      2\n",
       "constructon     1\n",
       "threapist       1\n",
       "ansewr          1\n",
       "Length: 64439, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理後データ出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./data/processed_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('./data/processed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
